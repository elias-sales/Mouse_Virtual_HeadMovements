#Este código foi desenvolvido por Elias dos Santos Sales Junior, como parte da disciplina de Trabalho de Conclusão de Curso II 
#pela Universidade Federal do Sul e Sudeste do Pará
#Este software simula um mouse virtual através do rastreamento dos movimentos da cabeça e simula os cliques
#através da deteção das expressões faciais Olhos Fechados e ao Levantar as sobrancelhas
#Necessário possuir um arquivo Haascascade para detecção de face (caminho na linha 93).
#necessário o detector de expressões treinado (modelo_01_expressoes.h5 na linha 28) 
Os arquivos podem ser baixados no drive: https://drive.google.com/drive/folders/1hC-wAIKrOIpZw7qGqABe1HTspf_r9Pcm?usp=sharing

from __future__ import print_function
import cv2 as cv
import pyautogui
import numpy as np
import argparse
import tensorflow
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
tensorflow.__version__

x1=0
y1=0
w1=0
h1=0
restx=0
resty=0
resty2=0
restx2=0

caminho_modelo = r'C:\Users\elias\Documents\Eye_Tracking\TCC_2\Deteccao_facial\modelo_01_expressoes.h5'
classificador_emocoes = load_model(caminho_modelo, compile = False)
expressoes = ["Olhos fechados", "Sobrancelha Alta"]
#--------------------------------------------------------------------------------------------------------

def detectAndDisplay(frame):

    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)# TRANSFORMA O FRAME PARA ESCALA DE CINZA

    frame_gray = cv.equalizeHist(frame_gray)#Faz a equalização de histograma para dar mais contraste à imagem

    faces = face_cascade.detectMultiScale(frame_gray) #Retorna uma matriz np.array de 1x4 que detereminam a posição do rosto

    for (x,y,w,h) in faces:

        center = (x + w//2, y + h//2)
        frame = cv.ellipse(frame, center, (w//2, h//2), 0, 0, 360, (0, 255, 0), 2)
        faceROI = frame_gray[y:y+h,x:x+w]
        #cv.imshow('Capture - Face detection', faceROI)
        roi = cv.resize(faceROI, (48, 48))
        #cv.imshow('Capture - Face detection', roi)
        roi = roi / 255
        roi = img_to_array(roi)  # Função do próprio tensorFlow para adicionar 1 canal a mais (48x48,1) "somente uma cor" ; transformou imagem para array
        roi = np.expand_dims(roi,axis=0)
        preds = classificador_emocoes.predict(roi)[0]
        MaximoValor = preds.argmax()
        label = expressoes[MaximoValor]
        #Parte do Click na mesma função para aproveitar a detecção facial




        if preds[1] >= 0.8:
            print("Click",preds[0])
            pyautogui.click()
        if preds[0] >= 0.9998:
            print("direito Click",preds[1])
            pyautogui.rightClick()
        if preds[0] < 0.9999 and preds[1] < 0.7:
            print("Neutro")


        # expand_dims expande as dimensões.(Temos uma imagem, com 48 de largura e altura e 1 canal só que é a escala de cinza)
        # Este é o formato que o Tensor Flow requer para fazer as detecções.

    cv.imshow('Capture - Face detection', frame)#EXIBE A ELIPSE NO FRAME ATUAL

    return faces

#--------------------------------------------------------------------------------------------------------
def mousemove(mediaRestx, mediaResty):
    #print(mediaRestx, mediaResty)
    if -2 > mediaRestx < 2 and -2 > mediaResty < 2:
        mediaRestx = 0
        mediaResty = 0

    pyautogui.move(mediaRestx * 14, mediaResty * -16)



# --------------------------------------------------------------------------------------------------------


parser = argparse.ArgumentParser(description='Code for Cascade Classifier tutorial.')

parser.add_argument('--face_cascade',help='Path to face cascade.',default=r'C:\Users\elias\Documents\Eye_Tracking\TCC_2\Deteccao_facial\haarcascade_frontalface_alt.xml')
parser.add_argument('--camera',help='Camera divide number.',type=int,default=0)

args = parser.parse_args()

face_cascade_name = args.face_cascade

face_cascade = cv.CascadeClassifier()

#-- 1. Carrega o modelo
if not face_cascade.load(cv.samples.findFile(face_cascade_name)):
    print('--(!)Error loading face cascade')
    exit(0)
camera_device = args.camera
#-- 2. Lê o fluxo de vídeo
cap = cv.VideoCapture(camera_device)
if not cap.isOpened:
    print('--(!)Error opening video capture')
    exit(0)


while True: #Laço principal que mantém a detecção de rosto ativa
    pyautogui.FAILSAFE = False #Remove a trava de segurança que faz o programa parar de rodar ao encontrar a extremidade da tela
    ret, frame = cap.read() #faz a captura da imagem frame a frame
    if frame is None:
        print('--(!) No captured frame -- Break!')
        break
    if cv.waitKey(10) == 27:
        break

    positions=detectAndDisplay(frame) #Chama a Função que detecta o rosto e retorna os valores para o desenho do círculo


    for (x, y, w, h) in positions: #este laço serve para carregar os valores do ndarray positions
        x=int(x+(w/2))

        if x != x1:               # se o valor atual de x for diferente da anterior
            restx = x1 - x        # Faço a subtração para encontrar a diferença entre os dois
            mediaRestx = (restx+restx2)/2 #Faço uma média entre os dois ultimos valores encontrados para suavizar o movimento
            mediaRestx = int(mediaRestx)
            restx2 = restx
            x1 = x                #igualo as variáveis armazenando o valor de x1 que será usado na próxima vez

        if y != y1:
            resty = y1 - y
            mediaResty = (resty+resty2)/2
            mediaResty = int(mediaResty)
            resty2 = resty
            y1 = y

        if -20 < mediaRestx < 20 and -20 < mediaResty < 20:
            mousemove(mediaRestx,mediaResty) #Chama a função que faz a movimentação do mouse


